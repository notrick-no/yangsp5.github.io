<!DOCTYPE html>
<html lang="zh-cn" data-theme="light">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>我的学习小屋 - 记录我的学习</title>
  <meta name="author" content="yangsp5">
  <meta name="copyright" content="yangsp5">
  <meta name="format-detection" content="telephone=no">
  <meta name="theme-color" content="#ffffff">
  <meta property="og:type" content="website">
  <meta property="og:title" content="我的学习小屋">
  <meta property="og:url" content="http://yangsp5.github.io/index.html">
  <meta property="og:site_name" content="我的学习小屋">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:image" content="http://yangsp5.github.io/img/katto.jpg">
  <meta property="article:author" content="yangsp5">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:image" content="http://yangsp5.github.io/img/katto.jpg">
  <link rel="shortcut icon" href="/img/favicon.png">
  <link rel="canonical" href="http://yangsp5.github.io/">
  <link rel="preconnect" href="//cdn.jsdelivr.net" />
  <link rel="preconnect" href="//busuanzi.ibruce.info" />
  <link rel="stylesheet" href="/css/index.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print"
    onload="this.media='all'">
  <script>const GLOBAL_CONFIG = {
      root: '/',
      algolia: undefined,
      localSearch: { "path": "search.xml", "languages": { "hits_empty": "We didn't find any results for the search: ${query}" } },
      translate: undefined,
      noticeOutdate: undefined,
      highlight: { "plugin": "highlighjs", "highlightCopy": true, "highlightLang": true, "highlightHeightLimit": false },
      copy: {
        success: 'Copy successfully',
        error: 'Copy error',
        noSupport: 'The browser does not support'
      },
      relativeDate: {
        homepage: true,
        post: false
      },
      runtime: '',
      date_suffix: {
        just: 'Just',
        min: 'minutes ago',
        hour: 'hours ago',
        day: 'days ago',
        month: 'months ago'
      },
      copyright: undefined,
      lightbox: 'fancybox',
      Snackbar: undefined,
      source: {
        jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
        justifiedGallery: {
          js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
          css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
        },
        fancybox: {
          js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
          css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
        }
      },
      isPhotoFigcaption: false,
      islazyload: false,
      isanchor: false
    }</script>
  <script id="config-diff">var GLOBAL_CONFIG_SITE = {
      isPost: false,
      isHome: true,
      isHighlightShrink: false,
      isToc: false,
      postUpdate: '2021-05-08 10:31:40'
    }</script><noscript>
    <style type="text/css">
      #nav {
        opacity: 1
      }

      .justified-gallery img {
        opacity: 1
      }

      #recent-posts time,
      #post-meta time {
        display: inline !important
      }
    </style>
  </noscript>
  <script>(win => {
                               win.saveToLocal = {
                                 set: function setWithExpiry(key, value, ttl) {
                                   if (ttl === 0) return
                                   const now = new Date()
                                   const expiryDay = ttl * 86400000
                                   const item = {
                                     value: value,
                                     expiry: now.getTime() + expiryDay,
                                   }
                                   localStorage.setItem(key, JSON.stringify(item))
                                 },

                                 get: function getWithExpiry(key) {
                                   const itemStr = localStorage.getItem(key)

                                   if (!itemStr) {
                                     return undefined
                                   }
                                   const item = JSON.parse(itemStr)
                                   const now = new Date()

                                   if (now.getTime() > item.expiry) {
                                     localStorage.removeItem(key)
                                     return undefined
                                   }
                                   return item.value
                                 }
                               }

                               win.getScript = url => new Promise((resolve, reject) => {
                                 const script = document.createElement('script')
                                 script.src = url
                                 script.async = true
                                 script.onerror = reject
                                 script.onload = script.onreadystatechange = function () {
                                   const loadState = this.readyState
                                   if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
                                   script.onload = script.onreadystatechange = null
                                   resolve()
                                 }
                                 document.head.appendChild(script)
                               })

                               win.activateDarkMode = function () {
                                 document.documentElement.setAttribute('data-theme', 'dark')
                                 if (document.querySelector('meta[name="theme-color"]') !== null) {
                                   document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
                                 }
                               }
                               win.activateLightMode = function () {
                                 document.documentElement.setAttribute('data-theme', 'light')
                                 if (document.querySelector('meta[name="theme-color"]') !== null) {
                                   document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
                                 }
                               }
                               const t = saveToLocal.get('theme')

                               if (t === 'dark') activateDarkMode()
                               else if (t === 'light') activateLightMode()

                               const asideStatus = saveToLocal.get('aside-status')
                               if (asideStatus !== undefined) {
                                 if (asideStatus === 'hide') {
                                   document.documentElement.classList.add('hide-aside')
                                 } else {
                                   document.documentElement.classList.remove('hide-aside')
                                 }
                               }
                             })(window)</script>
  <meta name="generator" content="Hexo 5.4.0">
</head>

<body>
  <div id="sidebar">
    <div id="menu-mask"></div>
    <div id="sidebar-menus">
      <div class="author-avatar"><img class="avatar-img" src="/img/katto.jpg"
          onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar" /></div>
      <div class="site-data">
        <div class="data-item is-center">
          <div class="data-item-link"><a href="/archives/">
              <div class="headline">Articles</div>
              <div class="length-num">39</div>
            </a></div>
        </div>
        <div class="data-item is-center">
          <div class="data-item-link"><a href="/tags/">
              <div class="headline">Tags</div>
              <div class="length-num">11</div>
            </a></div>
        </div>
        <div class="data-item is-center">
          <div class="data-item-link"><a href="/categories/">
              <div class="headline">Categories</div>
              <div class="length-num">12</div>
            </a></div>
        </div>
      </div>
      <hr />
      <div class="menus_items">
        <div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a>
        </div>
        <div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a>
        </div>
        <div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span>
              分类</span></a></div>
      </div>
    </div>
  </div>
  <div class="page" id="body-wrap">
    <header class="full_page" id="page-header" style="background-image: url('/img/top_img.jpg')">
      <nav id="nav"><span id="blog_name"><a id="site-name" href="/">我的学习小屋</a></span>
        <div id="menus">
          <div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span>
                Search</span></a></div>
          <div class="menus_items">
            <div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a>
            </div>
            <div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span>
                  标签</span></a></div>
            <div class="menus_item"><a class="site-page" href="/categories/"><i
                  class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div>
          </div>
          <div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div>
        </div>
      </nav>
      <div id="site-info">
        <h1 id="site-title">我的学习小屋</h1>
      </div>
      <div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div>
    </header>
    <main class="layout" id="content-inner">
      <div class="recent-posts" id="recent-posts">
        <div class="recent-post-item">
          <div class="post_cover left_radius"><a
              href="/2021/04/23/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-LSTM/" title="经典论文阅读---LSTM">
              <img class="post_bg" src="/img/top_img.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'"
                alt="经典论文阅读---LSTM"></a></div>
          <div class="recent-post-info"><a class="article-title"
              href="/2021/04/23/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-LSTM/"
              title="经典论文阅读---LSTM">经典论文阅读---LSTM</a>
            <div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span
                  class="article-meta-label">Created</span><time class="post-meta-date-created"
                  datetime="2021-04-23T03:30:07.000Z" title="Created 2021-04-23 11:30:07">2021-04-23</time><span
                  class="article-meta__separator">|</span><i class="fas fa-history"></i><span
                  class="article-meta-label">Updated</span><time class="post-meta-date-updated"
                  datetime="2021-05-07T23:51:17.287Z" title="Updated 2021-05-08 07:51:17">2021-05-08</time></span><span
                class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a
                  class="article-meta__categories" href="/categories/nlp/">nlp</a><i class="fas fa-angle-right"></i><a
                  class="article-meta__categories"
                  href="/categories/nlp/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87/">经典论文</a></span></div>
            <div class="content">
              记录下LSTM

              本文解决了什么问题
              在摘要中提到了，传统的BPTT或RTRL会出现，误差（就是梯度）消失、爆炸的问题；梯度消失会导致更新过慢，甚至不能学习，梯度爆炸会导致权重震荡
              RNN和Lstm的不同之处，在于改进了RNN的梯度爆炸、消失问题
              本文利用lstm的结构，改进了这个问题，整个结构使得恒定的error flow，不会梯度爆炸、消失（感觉是吹的）

              BPTT
              BPTT是back propagation throught time，是梯度沿时间通道传播的算法

              假设在时间$t$，真实值（文中说的target）是$d_{k}(t)$，$k$指第$k$个值；预测值为$y^{k}$

              有一说一，原论文的公式写得太简洁了
              如果损失函数是mse，即


              loss = \sum_t \sum_k \left( d_k(t) - y^k(t) \right)^2
              那么第$k$的单元的误差就是，对第$k$个神经元求导，即$\frac{\partial \text{loss}}{\partial net_k(t)} = \vartheta_{k}(t)$
              文中把这个叫做$k’s$ error ...</div>
          </div>
        </div>
        <div class="recent-post-item">
          <div class="post_cover right_radius"><a
              href="/2021/04/14/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-RNN/" title="经典论文阅读---RNN"> <img
                class="post_bg" src="/img/top_img.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'"
                alt="经典论文阅读---RNN"></a></div>
          <div class="recent-post-info"><a class="article-title"
              href="/2021/04/14/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-RNN/"
              title="经典论文阅读---RNN">经典论文阅读---RNN</a>
            <div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span
                  class="article-meta-label">Created</span><time class="post-meta-date-created"
                  datetime="2021-04-14T08:21:48.000Z" title="Created 2021-04-14 16:21:48">2021-04-14</time><span
                  class="article-meta__separator">|</span><i class="fas fa-history"></i><span
                  class="article-meta-label">Updated</span><time class="post-meta-date-updated"
                  datetime="2021-04-18T12:18:38.264Z" title="Updated 2021-04-18 20:18:38">2021-04-18</time></span><span
                class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a
                  class="article-meta__categories" href="/categories/nlp/">nlp</a><i class="fas fa-angle-right"></i><a
                  class="article-meta__categories"
                  href="/categories/nlp/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87/">经典论文</a></span></div>
            <div class="content">
              没想到这篇文章时代如此久远，是Rumelhart David E、Hinton Geoffrey E、Williams Ronald J 三位大神在1985年发表的
              年代久远，以至于没有数字版本的pdf。。。
              阅读这篇文章，了解最开始的RNN的想法
              这篇文章不知道有几个版本，我找到的每篇都不太一样。。

              http://www.cs.utoronto.ca/，这份pdf只有四页，这篇文章的题目是Learning representations by back-propagating errors
              stanford的版本，足足23页；这篇文章的题目是learning internal representations by error propagation
              这两个不一样，本文主要讲第一个文章


              首先文章描述了一种新的学习过程，反向传播；这种学习过程是神经元的学习过程

              这个过程，就是重复的调整权重，来最小化网络输出值和真实值之间的差距
              由于权重的不过调整，所以中间的隐藏单元就可以来表示重要的特征
              文章在第一段就提到，如果不加隐藏神经元，那么，输入和输出是直接相连的，所以上面提到的调整权 ...</div>
          </div>
        </div>
        <div class="recent-post-item">
          <div class="post_cover left_radius"><a
              href="/2021/04/11/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-word2vec/"
              title="经典论文阅读---word2vec"> <img class="post_bg"
                src="/2021/04/11/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-word2vec/word2vec.png"
                onerror="this.onerror=null;this.src='/img/404.jpg'" alt="经典论文阅读---word2vec"></a></div>
          <div class="recent-post-info"><a class="article-title"
              href="/2021/04/11/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-word2vec/"
              title="经典论文阅读---word2vec">经典论文阅读---word2vec</a>
            <div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span
                  class="article-meta-label">Created</span><time class="post-meta-date-created"
                  datetime="2021-04-11T13:03:31.000Z" title="Created 2021-04-11 21:03:31">2021-04-11</time><span
                  class="article-meta__separator">|</span><i class="fas fa-history"></i><span
                  class="article-meta-label">Updated</span><time class="post-meta-date-updated"
                  datetime="2021-04-20T07:04:54.632Z" title="Updated 2021-04-20 15:04:54">2021-04-20</time></span><span
                class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a
                  class="article-meta__categories" href="/categories/nlp/">nlp</a><i class="fas fa-angle-right"></i><a
                  class="article-meta__categories"
                  href="/categories/nlp/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87/">经典论文</a></span></div>
            <div class="content">
              Efficient Estimation of Word Representations in Vector Space
              Distributed Representations of Words and Phrases and their Compositionality
              第一篇文章在NNLM的基础上做了修改，提出了CBOW和skip-gram模型
              第二篇文章暂时还没看，大概是讲skip-gram的
              这里感谢知乎的回答，大部分博客都只讲原理，不讲输入输出流，其实这对模型的理解不够
              知乎cbow 与 skip-gram的比较讲得比较好
              参考github博客和知乎，CSDN

              介绍
              首先提出了以往的NLP，大多将words视为原子级别的单位，不可再分；没有词之间的相关性这种概念。选择这种模型的好处是，简单、稳定、简单模型在大量数据训练的效果好优于复杂模型在小数据集上的效果。很有名的模型就是n-gram

              本文的目的是，学习高质量的word vectors，也就是词向量、NNLM中的feature vector

              在这篇文章之前，没有人可以在hundred of miilions of w ...</div>
          </div>
        </div>
        <div class="recent-post-item">
          <div class="post_cover right_radius"><a
              href="/2021/04/08/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-NNLM/" title="经典论文阅读---NNLM">
              <img class="post_bg"
                src="/2021/04/08/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-NNLM/model.png"
                onerror="this.onerror=null;this.src='/img/404.jpg'" alt="经典论文阅读---NNLM"></a></div>
          <div class="recent-post-info"><a class="article-title"
              href="/2021/04/08/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-NNLM/"
              title="经典论文阅读---NNLM">经典论文阅读---NNLM</a>
            <div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span
                  class="article-meta-label">Created</span><time class="post-meta-date-created"
                  datetime="2021-04-08T13:32:49.000Z" title="Created 2021-04-08 21:32:49">2021-04-08</time><span
                  class="article-meta__separator">|</span><i class="fas fa-history"></i><span
                  class="article-meta-label">Updated</span><time class="post-meta-date-updated"
                  datetime="2021-04-11T12:58:41.749Z" title="Updated 2021-04-11 20:58:41">2021-04-11</time></span><span
                class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a
                  class="article-meta__categories" href="/categories/nlp/">nlp</a><i class="fas fa-angle-right"></i><a
                  class="article-meta__categories"
                  href="/categories/nlp/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87/">经典论文</a></span></div>
            <div class="content">
              NNLM，是非常经典的NLP论文，这是第一篇将神经网络引入nlp的论文，应该反复咀嚼文中的思想
              下面以翻译的形式慢慢解读

              介绍123456A fundamental problem that makes language modeling and other learning problems difficult is
              thecurse of dimensionality. It is particularly obvious in the case when one wants to model the
              jointdistribution between many discrete random variables (such as words in a sentence, or discrete
              attributes in a data-mining task).

              上面提到了对语言模型建模的困难：维数灾难
              文中给出的例子是：假设我们的字典有10万个词语，现在需要对10个词语进行建模，那么这10个词语的概率就是$100000^{10}-1=10^{50} - 1$个参数
              10 ...</div>
          </div>
        </div>
        <div class="recent-post-item">
          <div class="post_cover left_radius"><a href="/2021/04/07/wenet%E8%AE%AD%E7%BB%83%E7%AC%94%E8%AE%B0/"
              title="wenet训练笔记"> <img class="post_bg" src="/img/top_img.jpg"
                onerror="this.onerror=null;this.src='/img/404.jpg'" alt="wenet训练笔记"></a></div>
          <div class="recent-post-info"><a class="article-title"
              href="/2021/04/07/wenet%E8%AE%AD%E7%BB%83%E7%AC%94%E8%AE%B0/" title="wenet训练笔记">wenet训练笔记</a>
            <div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span
                  class="article-meta-label">Created</span><time class="post-meta-date-created"
                  datetime="2021-04-07T15:32:47.000Z" title="Created 2021-04-07 23:32:47">2021-04-07</time><span
                  class="article-meta__separator">|</span><i class="fas fa-history"></i><span
                  class="article-meta-label">Updated</span><time class="post-meta-date-updated"
                  datetime="2021-04-09T10:25:49.604Z" title="Updated 2021-04-09 18:25:49">2021-04-09</time></span></div>
            <div class="content">1234567# 这两个是配置环境，在path.sh下修改 &#x2F;KALDI_ROOT的地址. .&#x2F;path.sh || exit 1;.
              .&#x2F;cmd.sh || exit 1;nj&#x3D;16feat_dir&#x3D;fbankdict&#x3D;data&#x2F;dict&#x2F;lang_char.txt # 字典位置
              step -1
              这一步是下载数据

              123#
              data是数据存放地址，自己下载了的话，就修改位置data&#x3D;&#x2F;export&#x2F;data&#x2F;asr-data&#x2F;OpenSLR&#x2F;33&#x2F;data_url&#x3D;www.openslr.org&#x2F;resources&#x2F;33
              step 0
              这个是数据准备，在wenet的s0里面只调用了local/aishell_data_prep.sh，在s1里面还用了kaldi

              123456789101112# aishell_data_prep.sh# 输入两个地址， $&#123;data&#125;&#x2F;da ...</div>
          </div>
        </div>
        <div class="recent-post-item">
          <div class="post_cover right_radius"><a href="/2021/04/07/transformer-xl/" title="transformer-xl"> <img
                class="post_bg" src="/2021/04/07/transformer-xl/figure_2.png"
                onerror="this.onerror=null;this.src='/img/404.jpg'" alt="transformer-xl"></a></div>
          <div class="recent-post-info"><a class="article-title" href="/2021/04/07/transformer-xl/"
              title="transformer-xl">transformer-xl</a>
            <div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span
                  class="article-meta-label">Created</span><time class="post-meta-date-created"
                  datetime="2021-04-07T05:40:11.000Z" title="Created 2021-04-07 13:40:11">2021-04-07</time><span
                  class="article-meta__separator">|</span><i class="fas fa-history"></i><span
                  class="article-meta-label">Updated</span><time class="post-meta-date-updated"
                  datetime="2021-04-07T15:08:11.442Z" title="Updated 2021-04-07 23:08:11">2021-04-07</time></span><span
                class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a
                  class="article-meta__categories" href="/categories/nlp/">nlp</a></span></div>
            <div class="content">transformer-xl
              记录下学习transformer-xl的内容
              这篇文章主要是在原来的transformer的基础上改进了长度列
              整个模型的改动就在下面的公式了


              \begin{aligned}
              \widetilde{\mathbf{h}}_{\tau}^{n-1}=&\left[\mathrm{SG}\left(\mathbf{m}_{\tau}^{n-1}\right) \circ
              \mathbf{h}_{\tau}^{n-1}\right] \\
              \mathbf{q}_{\tau}^{n}, \mathbf{k}_{\tau}^{n}, \mathbf{v}_{\tau}^{n}=& \mathbf{h}_{\tau}^{n-1}
              \mathbf{W}_{q}^{n \top}, \widetilde{\mathbf{h}}_{\tau}^{n-1} \mathbf{W}_{k, E}^{n} \top,
              \widetilde{\mathbf{h}}_{\tau}^{n-1} \mathbf{W}_{v}^{n \top} \\
              \mathbf{A}_{\tau, ...</div>
          </div>
        </div>
        <div class="recent-post-item">
          <div class="post_cover left_radius"><a href="/2020/12/30/tokenizer/" title="tokenizer"> <img class="post_bg"
                src="/img/top_img.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="tokenizer"></a></div>
          <div class="recent-post-info"><a class="article-title" href="/2020/12/30/tokenizer/"
              title="tokenizer">tokenizer</a>
            <div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span
                  class="article-meta-label">Created</span><time class="post-meta-date-created"
                  datetime="2020-12-30T08:06:37.000Z" title="Created 2020-12-30 16:06:37">2020-12-30</time><span
                  class="article-meta__separator">|</span><i class="fas fa-history"></i><span
                  class="article-meta-label">Updated</span><time class="post-meta-date-updated"
                  datetime="2021-02-27T14:36:07.000Z" title="Updated 2021-02-27 22:36:07">2021-02-27</time></span><span
                class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a
                  class="article-meta__categories" href="/categories/nlp/">nlp</a></span></div>
            <div class="content">
              记录下分词器是怎么做的
              主要参考来源tokenizer_summary和其他的做法

              一、transformers里面的分词器
              transformers里面有BertTokenizer，GPT-2，RoBERTa,，XLM

              文章中提到多种字典的相似度

              bert分词器的实验


              二、如何将句子分成一个个token1、基于空格分词
              最简单的方法，使用空格分词，bert的pretokenizer就是这么做的

              123&quot;Don&#x27;t you love 🤗 Transformers? We sure do.&quot;.split(&quot; &quot;)#
              结果[&quot;Don&#x27;t&quot;, &#x27;you&#x27;, &#x27;love&#x27;, &#x27;🤗&#x27;, &#x27;Transformers?&#x27;,
              &#x27;We&#x27;, &#x27;sure&#x27;, &#x27;do.&#x27;]

              上面的做法有一点不好，没有考虑词根的问题，如Transformers?与Transformer是一样 ...</div>
          </div>
        </div>
        <div class="recent-post-item">
          <div class="post_cover right_radius"><a href="/2020/12/23/loss%E4%BC%98%E5%8C%96/" title="loss优化"> <img
                class="post_bg" src="/img/top_img.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'"
                alt="loss优化"></a></div>
          <div class="recent-post-info"><a class="article-title" href="/2020/12/23/loss%E4%BC%98%E5%8C%96/"
              title="loss优化">loss优化</a>
            <div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span
                  class="article-meta-label">Created</span><time class="post-meta-date-created"
                  datetime="2020-12-23T03:32:38.000Z" title="Created 2020-12-23 11:32:38">2020-12-23</time><span
                  class="article-meta__separator">|</span><i class="fas fa-history"></i><span
                  class="article-meta-label">Updated</span><time class="post-meta-date-updated"
                  datetime="2020-12-23T12:13:42.605Z" title="Updated 2020-12-23 20:13:42">2020-12-23</time></span></div>
            <div class="content">
              这篇是我在看完bert预训练之后，bert的两个任务的loss直接加起来，之后去学习怎么调整loss
              这里参考了天池比赛给出的loss调整方法：
              第一篇是Multi-task learning using uncertainty to weigh losses for scene geometry and semantics
              第二篇是Dynamic task prioritization for multitask learning
              第三篇是End-to-End Multi-Task Learning with Attention



              第一篇
              这篇文章是cv里面的，但是它讲了两种loss的组合方式，第一种是连续性的output（如输出某个物体的距离，文章中的depth
              regression），第二种是分类的output（如语义分割，每个像素点是不是边界）
              假设我们的模型输出值是$\mathbf{f}^{\mathbf{W}}(\mathbf{x})$，这里的$\mathbf{x}$是模型的输入值，如[batch_size, seq_len,
              hidden_size]这种，$\mat ...</div>
          </div>
        </div>
        <div class="recent-post-item">
          <div class="post_cover left_radius"><a href="/2020/12/14/bert/" title="bert"> <img class="post_bg"
                src="/2020/12/14/bert/bert.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="bert"></a>
          </div>
          <div class="recent-post-info"><a class="article-title" href="/2020/12/14/bert/" title="bert">bert</a>
            <div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span
                  class="article-meta-label">Created</span><time class="post-meta-date-created"
                  datetime="2020-12-14T02:27:44.000Z" title="Created 2020-12-14 10:27:44">2020-12-14</time><span
                  class="article-meta__separator">|</span><i class="fas fa-history"></i><span
                  class="article-meta-label">Updated</span><time class="post-meta-date-updated"
                  datetime="2020-12-15T03:35:53.270Z" title="Updated 2020-12-15 11:35:53">2020-12-15</time></span><span
                class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a
                  class="article-meta__categories" href="/categories/nlp/">nlp</a></span></div>
            <div class="content">
              由于已经了解了transformer了
              这篇博客记录下bert是怎么做预训练、fine tune，并以源码形式的展示
              源码网址

              数据的清洗
              数据的清洗代表了，训练的方法
              样本数据一共有三篇短文（以空行分隔），每一行为一个自然句子，下面展示两篇短文

              读取文章，并转成unicode的形式

              将句子分词，就是tokenize

              取一篇文章，我们允许的句子最大长度是max_seq_length=128，但每个句子会加上[CLS] [SEP]
              [SEP]，所以从文章的句子中抽取的句子长度是max_num_tokens=128-125，所以我们目标取出的target_seq_length=max_num_tokens=125

              注意，通常希望把序列的长度填充到最大长度，所以短的句子浪费计算消耗，但有时候（大概10%的时候）希望采用短句来最小化预训练和微调的差异，所以源码中有short_seq_prob=0.1，以这个概率生成短句子，就是target_seq_length=[2,
              ..., 125]

              源码中维护了一个chunk，用了不断的添加句子进去，直到这个chunk的token数量超过t ...</div>
          </div>
        </div>
        <div class="recent-post-item">
          <div class="post_cover right_radius"><a href="/2020/12/10/dropout/" title="dropout"> <img class="post_bg"
                src="/2020/12/10/dropout/dropout_net.png" onerror="this.onerror=null;this.src='/img/404.jpg'"
                alt="dropout"></a></div>
          <div class="recent-post-info"><a class="article-title" href="/2020/12/10/dropout/" title="dropout">dropout</a>
            <div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span
                  class="article-meta-label">Created</span><time class="post-meta-date-created"
                  datetime="2020-12-10T05:55:48.000Z" title="Created 2020-12-10 13:55:48">2020-12-10</time><span
                  class="article-meta__separator">|</span><i class="fas fa-history"></i><span
                  class="article-meta-label">Updated</span><time class="post-meta-date-updated"
                  datetime="2020-12-10T07:17:57.000Z" title="Updated 2020-12-10 15:17:57">2020-12-10</time></span><span
                class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a
                  class="article-meta__categories" href="/categories/nlp/">nlp</a></span></div>
            <div class="content">
              这篇文章记录下dropout的原文阅读，以及它提出来的想法
              原文是Dropout: A Simple Way to Prevent Neural Networks from Overfitting

              什么是dropout
              在神经网络中，很容易过拟合，dropout的第一个想法就是希望可以缓解过拟合
              dropout的核心思想就是以概率$p$随机保留网络中的一个单元
              如下图，左边一个全连接的前馈神经网络
              右边是随机去掉一些单元后，一个子网络，也叫thinned networks


              为什么dropout有用
              缓解过拟合的方法，最直观的想法就是：加权平均，我们建立多个预测模型，将最后的预测值加权平均
              上述想法在小的网络、模型中比较有效，但是如果模型非常大，那么就很难计算了
              如权重怎么求
              怎么生成多个模型？要么模型结构不一样，要么数据集不一样


              上述想法的一种逼近方法就是，生成数量为指数阶的模型，将这些模型的预测值求等权重的几何平均，这些模型是共享权重的
              dropout就是上面逼近方法的技术
              在训练过程中，下面的$l$是第$l$层网络，$\mathbf{y}^{(l)}$是某个样本第$l$ ...</div>
          </div>
        </div>
        <nav id="pagination">
          <div class="pagination"><span class="page-number current">1</span><a class="page-number"
              href="/page/2/#content-inner">2</a><span class="space">&hellip;</span><a class="page-number"
              href="/page/4/#content-inner">4</a><a class="extend next" rel="next" href="/page/2/#content-inner"><i
                class="fas fa-chevron-right fa-fw"></i></a></div>
        </nav>
      </div>
      <div class="aside-content" id="aside-content">
        <div class="card-widget card-info">
          <div class="card-info-avatar is-center"><img class="avatar-img" src="/img/katto.jpg"
              onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar" />
            <div class="author-info__name">yangsp5</div>
            <div class="author-info__description"></div>
          </div>
          <div class="card-info-data">
            <div class="card-info-data-item is-center"><a href="/archives/">
                <div class="headline">Articles</div>
                <div class="length-num">39</div>
              </a></div>
            <div class="card-info-data-item is-center"><a href="/tags/">
                <div class="headline">Tags</div>
                <div class="length-num">11</div>
              </a></div>
            <div class="card-info-data-item is-center"><a href="/categories/">
                <div class="headline">Categories</div>
                <div class="length-num">12</div>
              </a></div>
          </div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener"
            href="https://github.com/yangsp5"><i class="fab fa-github"></i><span>Follow Me</span></a>
        </div>
        <div class="sticky_layout">
          <div class="card-widget card-categories">
            <div class="item-headline">
              <i class="fas fa-folder-open"></i>
              <span>Categories</span>
              <a class="card-more-btn" href="/categories/" title="More">
                <i class="fas fa-angle-right"></i></a>
            </div>
            <ul class="card-category-list" id="aside-cat-list">
              <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/nlp/"><span
                    class="card-category-list-name">nlp</span><span class="card-category-list-count">10</span></a>
                <ul class="card-category-list child">
                  <li class="card-category-list-item "><a class="card-category-list-link"
                      href="/categories/nlp/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87/"><span
                        class="card-category-list-name">经典论文</span><span class="card-category-list-count">4</span></a>
                  </li>
                </ul>
              </li>
              <li class="card-category-list-item "><a class="card-category-list-link"
                  href="/categories/%E5%87%B8%E5%88%86%E6%9E%90/"><span class="card-category-list-name">凸分析</span><span
                    class="card-category-list-count">2</span></a></li>
              <li class="card-category-list-item "><a class="card-category-list-link"
                  href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"><span class="card-category-list-name">数据库</span><span
                    class="card-category-list-count">5</span></a></li>
              <li class="card-category-list-item "><a class="card-category-list-link"
                  href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span
                    class="card-category-list-name">机器学习</span><span class="card-category-list-count">1</span></a></li>
              <li class="card-category-list-item "><a class="card-category-list-link"
                  href="/categories/%E6%9D%82%E7%B1%BB/"><span class="card-category-list-name">杂类</span><span
                    class="card-category-list-count">1</span></a></li>
              <li class="card-category-list-item "><a class="card-category-list-link"
                  href="/categories/%E7%94%9F%E5%AD%98%E5%88%86%E6%9E%90/"><span
                    class="card-category-list-name">生存分析</span><span class="card-category-list-count">1</span></a></li>
              <li class="card-category-list-item "><a class="card-category-list-link"
                  href="/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span
                    class="card-category-list-name">神经网络</span><span class="card-category-list-count">1</span></a></li>
            </ul>
          </div>
          <div class="card-widget card-tags">
            <div class="item-headline"><i class="fas fa-tags"></i><span>Tags</span></div>
            <div class="card-tag-cloud"><a href="/tags/LSTM/" style="font-size: 1.1em; color: #999">LSTM</a> <a
                href="/tags/R/" style="font-size: 1.1em; color: #999">R</a> <a href="/tags/Transformer/"
                style="font-size: 1.1em; color: #999">Transformer</a> <a href="/tags/bert/"
                style="font-size: 1.1em; color: #999">bert</a> <a href="/tags/dropout/"
                style="font-size: 1.1em; color: #999">dropout</a> <a href="/tags/matlab/"
                style="font-size: 1.1em; color: #999">matlab</a> <a href="/tags/%E4%BF%A1%E5%BA%A6%E5%88%86%E6%9E%90/"
                style="font-size: 1.1em; color: #999">信度分析</a> <a href="/tags/%E5%8D%9A%E5%AE%A2/"
                style="font-size: 1.1em; color: #999">博客</a> <a
                href="/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"
                style="font-size: 1.1em; color: #999">正则表达式</a> <a href="/tags/%E7%88%AC%E8%99%AB/"
                style="font-size: 1.1em; color: #999">爬虫</a> <a href="/tags/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/"
                style="font-size: 1.1em; color: #999">语音识别</a></div>
          </div>
        </div>
      </div>
    </main>
    <footer id="footer" style="background-image: url('/img/top_img.jpg')">
      <div id="footer-wrap">
        <div class="copyright">&copy;2019 - 2021 By yangsp5</div>
        <div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener"
            href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank"
            rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div>
      </div>
    </footer>
  </div>
  <div id="rightside">
    <div id="rightside-config-hide"><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i
          class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button"
        title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div>
    <div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i
          class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="Back To Top"><i
          class="fas fa-arrow-up"></i></button></div>
  </div>
  <div id="local-search">
    <div class="search-dialog">
      <div class="search-dialog__title" id="local-search-title">Local search</div>
      <div id="local-input-panel">
        <div id="local-search-input">
          <div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts"
              type="text" /></div>
        </div>
      </div>
      <hr />
      <div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span>
    </div>
    <div id="search-mask"></div>
  </div>
  <div>
    <script src="/js/utils.js"></script>
    <script src="/js/main.js"></script>
    <script src="/js/search/local-search.js"></script>
    <div class="js-pjax"></div><canvas class="fireworks" mobile="false"></canvas>
    <script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script>
    <script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false"
      src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script>
    <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  </div>
</body>

</html>